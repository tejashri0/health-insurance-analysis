{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d841a42-2505-4815-8a6b-465fad9b0754",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "Health insurance premiums are influenced by a multitude of factors, ranging from individual characteristics like age and gender to broader lifestyle choices such as smoking and exercise habits. Understanding these variables and their impact on insurance charges is key for creating effective pricing models and offering competitive insurance plans. This project leverages a dataset from Kaggle, \"US Health Insurance Dataset,\" to predict health insurance charges based on various demographic and lifestyle factors.\n",
    "\n",
    "The objective of this project is to gain practical experience in predictive modeling, focusing on regression techniques such as linear regression and more advanced models like Random Forest and XGBoost. By analyzing the dataset, which includes features such as age, sex, BMI, smoking status, and region, the relationships between these factors and insurance charges are explored. Through careful data preprocessing, feature engineering, and model tuning, the goal is to develop a model that can accurately predict insurance charges while minimizing errors.\n",
    "\n",
    "In addition to refining predictive modeling skills, this project provides insight into the essential data preprocessing steps required for regression tasks, particularly in the context of healthcare data. Missing values are handled, categorical variables are encoded, and features are scaled and transformed to ensure optimal model performance. Ultimately, this project emphasizes the importance of understanding the factors influencing insurance pricing and the practical applications of regression in domains such as healthcare economics and insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d2c8cb-ce0d-4e03-801c-cececae41015",
   "metadata": {},
   "source": [
    "## **About the Data**\n",
    "\n",
    "The dataset used in this project is the \"US Health Insurance Dataset\", sourced from Kaggle. It provides information on individual medical charges billed by health insurance providers in the United States. This dataset serves as an excellent foundation for exploring regression techniques in a real-world healthcare context, where understanding the impact of personal and behavioral attributes on insurance costs is both practical and insightful.\n",
    "\n",
    "The dataset contains 1,338 entries and 7 features, along with the target variable charges. Each row represents a unique individual, capturing a range of attributes related to demographics, physical metrics, and lifestyle choices.\n",
    "Key Columns\n",
    "\n",
    "Below are some of the important columns examined to understand the data:\n",
    "\n",
    "    age: Age of the individual\n",
    "\n",
    "    sex: Gender of the individual (male or female)\n",
    "\n",
    "    bmi: Body Mass Index — a standard measure of body fat based on height and weight\n",
    "\n",
    "    children: Number of dependents covered by health insurance\n",
    "\n",
    "    smoker: Whether the person is a smoker (yes or no)\n",
    "\n",
    "    region: Geographic location within the U.S. (northeast, northwest, southeast, southwest)\n",
    "\n",
    "    charges: The medical costs billed to the individual (target variable)\n",
    "\n",
    "Initial Exploration and Insights\n",
    "\n",
    "To gain an initial understanding of the dataset, the following steps were performed:\n",
    "\n",
    "    Data Inspection: Summary statistics and .info() methods were used to understand data types, non-null counts, and the presence of missing values (none were found).\n",
    "\n",
    "    Categorical Distribution: Frequency counts were used to analyze distributions of categorical features like sex, smoker, and region.\n",
    "\n",
    "    Feature Relationships: Correlations among numerical features (e.g., age, bmi, children, charges) were evaluated using correlation matrices to identify patterns and potentially influential variables.\n",
    "\n",
    "    Outlier Detection: Boxplots and interquartile range (IQR) analysis were used to detect extreme values in the charges column, often driven by smoker status and high BMI levels.\n",
    "\n",
    "Although this section focuses on preprocessing, subsequent phases of the project will incorporate scatter plots and error analysis to visualize the effectiveness of different regression models—specifically, Linear Regression, Random Forest Regression, and XGBoost. These will help illustrate how well the models predict actual insurance charges and reveal areas where prediction accuracy could be improved.\n",
    "\n",
    "This dataset is publicly available at: [US Health Insurance Dataset](https://www.kaggle.com/datasets/teertha/ushealthinsurancedataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833cfb37-0bef-45b3-a0fe-d0539d4711ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      " age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "\n",
      "Preview:\n",
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520\n",
      "\n",
      "Columns: ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\n",
    "# Overview of the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nColumns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a60e60-82f8-433f-a457-47627cbca48d",
   "metadata": {},
   "source": [
    "## **Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06f2384-5cbe-4959-b6bc-4b126a5da840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape: (959, 9)\n",
      "y_train mean charges: 9738.038385693431\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "for col in ['age', 'bmi', 'children', 'charges']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "for col in ['sex', 'smoker', 'region']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "if 'sex' in df.columns:\n",
    "    df['sex'] = LabelEncoder().fit_transform(df['sex'])\n",
    "\n",
    "if 'smoker' in df.columns:\n",
    "    df['smoker'] = LabelEncoder().fit_transform(df['smoker'])\n",
    "\n",
    "# One-hot encode 'region'\n",
    "if 'region' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['region'], drop_first=True)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "for col in ['age', 'bmi', 'children']:\n",
    "    if col in df.columns:\n",
    "        df[[col]] = scaler.fit_transform(df[[col]])\n",
    "\n",
    "# Feature Engineering: Create interaction feature\n",
    "df['age_bmi'] = df['age'] * df['bmi']\n",
    "\n",
    "# Check for outliers using IQR\n",
    "Q1 = df['charges'].quantile(0.25)\n",
    "Q3 = df['charges'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df[(df['charges'] >= lower_bound) & (df['charges'] <= upper_bound)]\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('charges', axis=1)\n",
    "y = df['charges']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of the training set and mean charge in the training set\n",
    "print(\"\\nX_train shape:\", X_train.shape)\n",
    "print(\"y_train mean charges:\", y_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ae882-3b4d-4f61-b011-d156563b487f",
   "metadata": {},
   "source": [
    "Before training regression models to predict health insurance charges, several preprocessing steps were implemented to clean and prepare the dataset for effective learning. These transformations ensured the data was both consistent and well-suited for input into machine learning algorithms.\n",
    "\n",
    "#### 1. Handling Missing Values\n",
    "To maintain data integrity, missing values were handled using appropriate imputation strategies based on data type:\n",
    "\n",
    "- **Numerical columns** (`age`, `bmi`, `children`, `charges`) were imputed using the **median**. Median imputation is robust to outliers and ensures continuity of numerical trends without being skewed by extreme values.\n",
    "- **Categorical columns** (`sex`, `smoker`, `region`) were imputed with their **mode**, representing the most frequent category, which is a common and effective technique for nominal data.\n",
    "\n",
    "#### 2. Encoding Categorical Variables\n",
    "Machine learning models require numerical inputs. Thus, categorical variables were encoded as follows:\n",
    "\n",
    "- **Binary labels** like `sex` and `smoker` were encoded using **Label Encoding**, converting them into `0` and `1` to represent the categories efficiently.\n",
    "- The **`region`** column, which contains multiple categories, was transformed using **One-Hot Encoding**. This created binary columns for each region (excluding one to avoid multicollinearity via `drop_first=True`), allowing models to capture geographic influence on charges.\n",
    "\n",
    "#### 3. Feature Scaling\n",
    "To eliminate scale discrepancies across features, numerical variables (`age`, `bmi`, and `children`) were standardized using **StandardScaler**. This transformation adjusts features to have a mean of 0 and standard deviation of 1, which is essential for many algorithms to perform optimally, especially when features vary in scale.\n",
    "\n",
    "#### 4. Feature Engineering\n",
    "A new interaction feature, **`age_bmi`**, was created by multiplying `age` and `bmi`. This feature captures the potential compounding effect of age and body mass on medical expenses, providing the model with a richer representation of risk factors.\n",
    "\n",
    "#### 5. Outlier Removal\n",
    "Outliers in the target variable `charges` were addressed using the **Interquartile Range (IQR) method**. Data points falling outside 1.5 times the IQR from the first and third quartiles were removed. This helps reduce the skewness in the target distribution and improves model generalization.\n",
    "\n",
    "#### 6. Train-Test Split\n",
    "The cleaned dataset was divided into training and testing sets using an **80-20 split**. This approach reserves 20% of the data for final evaluation while training the model on the remaining 80%, enabling validation of model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81b862-2a96-4204-88b2-5f45ad3e592a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
